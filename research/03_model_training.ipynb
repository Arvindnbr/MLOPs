{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x:\\\\DL\\\\Projects\\\\MLOPs'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"x:\\DL\\Projects\\MLOPs\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    current_dset: Path\n",
    "    root_dir: Path\n",
    "    status_file_dir: Path\n",
    "    req_files: list\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class TrainLogConfig:\n",
    "    model: str\n",
    "    save_path: Path\n",
    "    mlflow_uri: str\n",
    "    experiment_name: str\n",
    "    model_name: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Params:\n",
    "    optimizer: str\n",
    "    lr0: float\n",
    "    save_period: int\n",
    "    batch: int\n",
    "    epochs: int\n",
    "    resume: bool\n",
    "    seed: int\n",
    "    imgsz: int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.MLOPs.constants import *\n",
    "from scripts.MLOPs.utils.common import read_yaml, create_directories\n",
    "#from scripts.MLOPs.entity.config_entity import *\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_dataingestion_config(self)-> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL= config.source_URL,\n",
    "            local_data= config.local_data,\n",
    "            unzip_dir= config.unzip_dir\n",
    "            )\n",
    "        return data_ingestion_config\n",
    "    \n",
    "    def get_datavalidation_config(self)->DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        create_directories([config.data_val_dir])\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            current_dset= config.current_dset,\n",
    "            root_dir=config.data_val_dir,\n",
    "            status_file_dir= config.data_val_status,\n",
    "            req_files= config.data_val_req\n",
    "            )\n",
    "        return data_validation_config\n",
    "    \n",
    "    def get_train_log_config(self)-> TrainLogConfig:\n",
    "        config = self.config.train_log_config\n",
    "        trainlogconfig = TrainLogConfig(\n",
    "            model= config.model,\n",
    "            save_path= config.save_path,\n",
    "            mlflow_uri= config.mlflow_uri,\n",
    "            experiment_name= config.experiment_name,\n",
    "            model_name= config.model_name\n",
    "        )\n",
    "        return trainlogconfig\n",
    "    \n",
    "    def get_params(self)-> Params:\n",
    "        param = self.config.param\n",
    "        params = Params(\n",
    "            optimizer = param.optimizer,\n",
    "            lr0 = param.lr0,\n",
    "            save_period = param.save_period,\n",
    "            batch = param.batch,\n",
    "            epochs = param.epochs,\n",
    "            resume = param.resume,\n",
    "            seed = param.seed,\n",
    "            imgsz = param.imgsz\n",
    "        )\n",
    "        return params\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a wrapper class to ensure pytorch_model is an instance of torch.nn.Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WrapperModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "    def predict(self, context, model_input):\n",
    "        # Convert the DataFrame back to a dictionary to pass to the YOLO model\n",
    "        data_dict = model_input.to_dict(orient=\"records\")[0]\n",
    "        return self.model(**data_dict)\n",
    "\n",
    "\n",
    "def convert_pt_to_pytorch_model(model_path):\n",
    "    # Load the .pt model\n",
    "    model = torch.load(model_path)\n",
    "    # Convert it to a PyTorch model if necessary\n",
    "    # For example:\n",
    "    # pytorch_model = YOLOl(your_model_arguments)\n",
    "    # Copy the parameters from the loaded model to the PyTorch model\n",
    "    # pytorch_model.load_state_dict(model.state_dict())\n",
    "    return model\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def on_train_end(trainer):\n",
    "        print('Training ended, logging artifacts...')\n",
    "        best_model_path = trainer.best\n",
    "        mlflow.log_artifact(best_model_path, \"model\")\n",
    "        \n",
    "        # Register the model in MLflow Model Registry\n",
    "        mlflow.register_model(\n",
    "            f\"runs:/{mlflow.active_run().info.run_id}/model\",\n",
    "            \"my_registered_model\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from ultralytics import YOLO\n",
    "from scripts.MLOPs.utils.common import get_highest_train_folder\n",
    "\n",
    "\n",
    "class YoloWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.results = None\n",
    "        self.results_df = None\n",
    "        self.data = None\n",
    "\n",
    "    def load_context(self, context: object):\n",
    "        \"\"\"Load Yolo model from context path\n",
    "\n",
    "        Args:\n",
    "            context (object): An MLFlow object that is used to define the path to the model.\n",
    "        \"\"\"\n",
    "        runs_f = get_highest_train_folder(\"runs/detect\")\n",
    "        #logging.info(f\"artifacts[path]: runs/detect/{runs_f}/weights/best.pt\")\n",
    "        self.model = YOLO(f\"runs/detect/{runs_f}/weights/best.pt\")\n",
    "\n",
    "    def reformat_data(self):\n",
    "        \"\"\"Reformat given dictionary object that was coerced into numpy arrays into str,int,flow\"\"\"\n",
    "        # For each key-value pair, convert value to string.\n",
    "        for key, value in self.data.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                self.data[key] = \",\".join(map(str, [value]))\n",
    "\n",
    "        # For each key-value pair, convert value to appropriate type.\n",
    "        for key, value in self.data.items():\n",
    "            if value.isnumeric():  # Check if the value is an integer\n",
    "                self.data[key] = int(value)\n",
    "            elif value.replace(\".\", \"\", 1).isdigit():  # Check if the value is a float\n",
    "                self.data[key] = float(value)\n",
    "            elif value.lower() in [\"true\", \"false\"]:  # Check if the value is a boolean\n",
    "                self.data[key] = value.lower() == \"true\"\n",
    "\n",
    "    def yolo_results_to_df(self):\n",
    "        \"\"\"Create Yolo results as a df\"\"\"\n",
    "        # Retrieve bounding boxes\n",
    "        boxes = self.results[0].boxes\n",
    "        # Map class to string names\n",
    "        names = []\n",
    "        for object_class in boxes.cls.numpy():\n",
    "            names.append(self.model.names[object_class])\n",
    "        # Create return df\n",
    "        self.results_df = pd.DataFrame(\n",
    "            np.c_[boxes.xyxy.numpy(), boxes.conf, boxes.cls.numpy(), np.array(names)],\n",
    "            columns=[\"X1\", \"Y1\", \"X2\", \"Y2\", \"conf\", \"cls\", \"names\"],\n",
    "        )\n",
    "\n",
    "    def predict(self, context: object, data: dict):\n",
    "        \"\"\"Wrapper function around Yolo's predict function. Results are returned as a pandas dataframe.\n",
    "\n",
    "        Args:\n",
    "            context (object): An MLFlow object that is used to define the path to the model.\n",
    "            data (dict): dictionary with source for inference and override parameters for the model.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        logging.info(f\"Data input: f{self.data}\")\n",
    "        # Reformat data\n",
    "        self.reformat_data()\n",
    "        logging.info(f\"Data after reformat: f{self.data}\")\n",
    "\n",
    "        # Pass inputs to predict\n",
    "        self.results = self.model.predict(**self.data)\n",
    "        # Transform results to pandas df\n",
    "        self.yolo_results_to_df()\n",
    "\n",
    "        return self.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "import os,sys\n",
    "import logging\n",
    "import torch\n",
    "import onnx, onnxruntime\n",
    "from mlflow.models import infer_signature, validate_serving_input, convert_input_example_to_serving_input\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "from scripts.MLOPs.exception import AppException\n",
    "from scripts.MLOPs.utils.common import get_highest_train_folder, get_random_file_from_folder\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: TrainLogConfig, val: DataValidationConfig, param: Params):\n",
    "        self.config = config\n",
    "        self.val = val\n",
    "        self.param = param\n",
    "\n",
    "    def validation_status(self):\n",
    "        with open(self.val.status_file_dir, 'r') as file:\n",
    "            status = file.read().strip()\n",
    "        key, value = status.split(':')\n",
    "        key = key.strip()\n",
    "        value = value.strip().lower()\n",
    "\n",
    "        if key != \"validation_status\":\n",
    "            raise ValueError(\"unexpected key in status file\")\n",
    "        \n",
    "        if value == 'true':\n",
    "            return True\n",
    "        elif value == 'false':\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(\"validation status is invalid\")\n",
    "        \n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        dataset_dir = self.val.current_dset\n",
    "        data_path = os.path.join( dataset_dir, \"data.yaml\")\n",
    "        logging.info(f\"Dataset location: {data_path}\")\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.cuda.current_device()\n",
    "            logging.info(f\"Device is running on: {torch.cuda.get_device_name(device)}\")\n",
    "        else:\n",
    "            logging.info(f\"CUDA is not available\")\n",
    "            device = \"cpu\"\n",
    "            logging.info(f\"Device to run on: {device}\")\n",
    "            logging.info(data_path)\n",
    "\n",
    "        model = self.config.model\n",
    "\n",
    "        os.makedirs(self.config.save_path, exist_ok=True)\n",
    "        # save_path = os.path.join(self.config.save_path,\"Trainedv8.pt\")\n",
    "        # Load a pretrained YOLOv8n model\n",
    "        model = YOLO(model)\n",
    "        # Train the model\n",
    "        model.train(\n",
    "            data=data_path,\n",
    "            optimizer = self.param.optimizer,\n",
    "            lr0 = self.param.lr0,\n",
    "            save_period = self.param.save_period,\n",
    "            batch = self.param.batch,\n",
    "            epochs = self.param.epochs,\n",
    "            resume = self.param.resume,\n",
    "            seed = self.param.seed,\n",
    "            imgsz = self.param.imgsz\n",
    "            )\n",
    "        # savepath = model.save(save_path)\n",
    "        return model\n",
    "    \n",
    "    def log_into_mlflow2(self):\n",
    "        settings.update({'mlflow': True})\n",
    "        settings.reset()\n",
    "        run_name = self.config.model_name\n",
    "        experiment_name = self.config.experiment_name\n",
    "        os.environ[\"MLFLOW_TRACKING_URI\"] = self.config.mlflow_uri\n",
    "        os.environ[\"MLFLOW_RUN\"] = run_name\n",
    "        print(\"MLFLOW_TRACKING_URI: \", os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "        mlflow.set_experiment(experiment_name=experiment_name)\n",
    "        with mlflow.start_run(run_name=run_name) as run:\n",
    "            run_id = run.info.run_id\n",
    "            print(f\"Current MLflow Run ID: {run_id}\")\n",
    "\n",
    "            dataset_dir = self.val.current_dset\n",
    "            data_path = os.path.join( dataset_dir, \"data.yaml\")\n",
    "            logging.info(f\"Dataset location: {data_path}\")\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.cuda.current_device()\n",
    "                logging.info(f\"Device is running on: {torch.cuda.get_device_name(device)}\")\n",
    "            else:\n",
    "                logging.info(f\"CUDA is not available\")\n",
    "                device = \"cpu\"\n",
    "                logging.info(f\"Device to run on: {device}\")\n",
    "                logging.info(data_path)\n",
    "\n",
    "            model = self.config.model\n",
    "\n",
    "            os.makedirs(self.config.save_path, exist_ok=True)\n",
    "            # save_path = os.path.join(self.config.save_path,\"Trainedv8.pt\")\n",
    "            # Load a pretrained YOLOv8n model\n",
    "            model = YOLO(model)\n",
    "            model.add_callback(\"on_train_end\", on_train_end)\n",
    "            # Train the model\n",
    "            results = model.train(\n",
    "                data=data_path,\n",
    "                optimizer = self.param.optimizer,\n",
    "                lr0 = self.param.lr0,\n",
    "                save_period = self.param.save_period,\n",
    "                batch = self.param.batch,\n",
    "                epochs = self.param.epochs,\n",
    "                resume = self.param.resume,\n",
    "                seed = self.param.seed,\n",
    "                imgsz = self.param.imgsz\n",
    "                )\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                \"Precision\": results.results_dict['metrics/precision(B)'],\n",
    "                \"Recall\": results.results_dict['metrics/recall(B)'],\n",
    "                \"mAP\": results.results_dict['metrics/mAP50-95(B)'],\n",
    "                \"mAP50\": results.results_dict['metrics/mAP50(B)'],\n",
    "            })\n",
    "            \n",
    "            h_folder = get_highest_train_folder(\"runs/detect\")\n",
    "            model_artifact = f\"runs/detect/{h_folder}\"\n",
    "            pytorch_model = convert_pt_to_pytorch_model(f\"{model_artifact}/weights/best.pt\")\n",
    "\n",
    "            # Wrap pytorch_model\n",
    "            wrapped_model = WrapperModel(pytorch_model)\n",
    "\n",
    "\n",
    "            # Save the wrapped_model with MLflow\n",
    "            mlflow.pytorch.log_model(wrapped_model, artifact_path=\"pytorch_model\" ,registered_model_name=run_name)\n",
    "            mlflow.pytorch.save_model(wrapped_model, path=f\"{model_artifact}/pytorch_model\",pip_requirements=\"requirements.txt\")\n",
    "            mlflow.log_artifacts(model_artifact, artifact_path=\"pytorch_model\")\n",
    "\n",
    "            mlflow.log_param(\"device\", device)\n",
    "            mlflow.log_param(\"optimizer\", self.param.optimizer)\n",
    "            mlflow.log_param(\"learning_rate\", self.param.lr0)\n",
    "            mlflow.log_param(\"batch_size\", self.param.batch)\n",
    "            mlflow.log_param(\"epochs\", self.param.epochs)\n",
    "\n",
    "            mlflow.end_run()\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "\n",
    "        settings.update({'mlflow': True})\n",
    "        settings.reset()\n",
    "        run_name = self.config.model_name\n",
    "        experiment_name = self.config.experiment_name\n",
    "        os.environ[\"MLFLOW_TRACKING_URI\"] = self.config.mlflow_uri\n",
    "        os.environ[\"MLFLOW_RUN\"] = run_name\n",
    "        \n",
    "        print(\"MLFLOW_TRACKING_URI: \", os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "        \n",
    "        # settings.update({'datasets_dir': \"X:\\DL\\Projects\\MLOPs\"})\n",
    "        mlflow.pytorch.autolog(log_models=True)\n",
    "        mlflow.set_experiment(experiment_name=experiment_name)\n",
    "        \n",
    "        with mlflow.start_run(run_name=run_name) as run: \n",
    "            #run_name is the name of the task.\n",
    "            run_id = run.info.run_id \n",
    "            #run_id is the directory name that will be stored within the MLFLOW_TRACKING_URI path.\n",
    "            print(run_id)\n",
    "            save_path = os.path.join(self.config.save_path,\"Trainedv8.pt\")\n",
    "            model = YOLO(save_path)\n",
    "            yolonnx = model.export(format=\"onnx\", dynamic= True)\n",
    "            yolonnx_model = onnx.load(yolonnx)\n",
    "            mlflow.onnx.log_model(yolonnx_model, \"YOLOv8n\")             ##logged model\n",
    "        mlflow.end_run()\n",
    "            \n",
    "    \n",
    "    \n",
    "    # def run_pipeline(self):\n",
    "    #     try:\n",
    "    #         with open()\n",
    "    #         self.train_model()\n",
    "    #     except Exception as e:\n",
    "    #         raise AppException(e, sys)\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        if (self.validation_status() == True):\n",
    "            try:\n",
    "                self.log_into_mlflow()\n",
    "            except Exception as e:\n",
    "                raise AppException(e, sys)\n",
    "        else:\n",
    "            logging.INFO(f\"Model training not run due to invalid dataset. \\n please ingest a valid dataset\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Registers model in MLFlow\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import logging\n",
    "import yaml\n",
    "import cloudpickle\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "# from scripts.mlflow_utils import model_wrapper\n",
    "# from scripts.mlflow_utils.model_wrapper import YoloWrapper\n",
    "\n",
    "\n",
    "def get_experiment_id(name: str):\n",
    "    \"\"\"Retrieve experiment if registered name, else create experiment.\n",
    "\n",
    "    Args:\n",
    "        name (str): Mlflow experiment name\n",
    "\n",
    "    Returns:\n",
    "        str: Mlfow experiment id\n",
    "    \"\"\"\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(name)\n",
    "        return exp_id\n",
    "    return exp.experiment_id\n",
    "\n",
    "\n",
    "def read_lines(path: str):\n",
    "    \"\"\"Given a path to a file, this function reads file, seperates the lines and returns a list of those separated lines.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to file\n",
    "\n",
    "    Returns:\n",
    "        list: List made of of file lines\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "\n",
    "def log_metrics(save_dir: str, log_results: bool = True):\n",
    "    \"\"\"Log metrics to Mlflow from the Yolo model outputs.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): Path to Yolo save directory, i.e - runs/train\n",
    "        log_results (bool): If True, the results are logged to MLflow server\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    try:\n",
    "        with open(save_dir / \"results.csv\", \"r\") as csv_file:\n",
    "            metrics_reader = csv.DictReader(csv_file)\n",
    "            metrics_list = []\n",
    "            for metrics in metrics_reader:\n",
    "                # Create an empty dictionary to store the updated key-value pairs for this row\n",
    "                updated_metrics = {}\n",
    "                # Iterate through the key-value pairs in this row's dictionary\n",
    "                for key, value in metrics.items():\n",
    "                    # Remove whitespace from the key\n",
    "                    key = key.strip()\n",
    "                    value = value.strip()\n",
    "                    # Remove extra strings in keys\n",
    "                    patterns = [\"(B)\", \"metrics/\"]\n",
    "                    for pattern in patterns:\n",
    "                        key = key.replace(pattern, \"\")\n",
    "                    # Add the updated key-value pair to the updated row dictionary\n",
    "                    try:\n",
    "                        # Add the updated key-value pair to the updated row dictionary\n",
    "                        updated_metrics[key] = float(value)\n",
    "                    except ValueError:\n",
    "                        logging.error(f\"ValueError: Could not convert {value} to float.\")\n",
    "                    metrics_list.append(updated_metrics)\n",
    "                    if log_results:\n",
    "                        mlflow.log_metrics(updated_metrics)\n",
    "        return metrics_list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FileNotFoundError: Could not find {save_dir / 'results.csv'}.\")\n",
    "    except IOError:\n",
    "        print(f\"IOError: Could not read {save_dir / 'results.csv'}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def register_model(experiment_name: str, model_name: str, save_dir: Path):\n",
    "    \"\"\"Registers a model with mlflow\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name of Mlfow experiment\n",
    "        model_name (str): Name that will be registered with Mlflow\n",
    "        save_dir (Path): Path object where the results of the Yolo model are saved. I.e 'runs' directory\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    logging.debug(f\"Save Directory: {save_dir}\")\n",
    "\n",
    "    '''model_path = get_path_w_extension(\n",
    "        path=save_dir, extension=\".pt\", limit=1, ignore_files=[\"last.pt\"]\n",
    "    )[0]'''\n",
    "    model_path = f\"{save_dir}/weights/best.pt\"\n",
    "    artifacts = {\"path\": model_path}\n",
    "\n",
    "    model = YoloWrapper()\n",
    "\n",
    "    exp_id = get_experiment_id(experiment_name)\n",
    "\n",
    "    #cloudpickle.register_pickle_by_value(model_wrapper)\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # Log some params\n",
    "        with open(save_dir / \"args.yaml\", \"r\") as param_file:\n",
    "            params = yaml.safe_load(param_file)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        log_metrics(save_dir, True)\n",
    "        mlflow.log_artifact(f\"{save_dir}/weights/best.pt\")\n",
    "        pip_reqs = read_lines(\"requirements.txt\")\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"model\",\n",
    "            python_model=model,\n",
    "            pip_requirements=pip_reqs,\n",
    "            artifacts=artifacts,\n",
    "            registered_model_name=model_name,\n",
    "        )\n",
    "        run_id = run.info.run_uuid\n",
    "        experiment_id = run.info.experiment_id\n",
    "        mlflow.end_run()\n",
    "        logging.info(f\"artifact_uri = {mlflow.get_artifact_uri()}\")\n",
    "        logging.info(f\"runID: {run_id}\")\n",
    "        logging.info(f\"experiment_id: {experiment_id}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-05 11:59:38,438: INFO: common: yaml file: config\\config.yaml loaded sucessfully]\n",
      "[2024-08-05 11:59:38,445: INFO: common: yaml file: params.yaml loaded sucessfully]\n",
      "[2024-08-05 11:59:38,447: INFO: common: created directory at artifacts]\n",
      "[2024-08-05 11:59:38,449: INFO: common: created directory at artifacts/data_validation]\n",
      "[2024-08-05 11:59:38,449: INFO: 4122740354: Dataset location: artifacts/data_ingestion/data\\data.yaml]\n",
      "[2024-08-05 11:59:38,449: INFO: 4122740354: CUDA is not available]\n",
      "[2024-08-05 11:59:38,451: INFO: 4122740354: Device to run on: cpu]\n",
      "[2024-08-05 11:59:38,452: INFO: 4122740354: artifacts/data_ingestion/data\\data.yaml]\n",
      "New https://pypi.org/project/ultralytics/8.2.73 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=artifacts/data_ingestion/data\\data.yaml, epochs=1, time=None, patience=100, batch=24, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train63, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.03, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train63\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\train\\labels.cache... 624 images, 0 backgrounds, 0 corrupt: 100%|██████████| 624/624 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\valid\\labels.cache... 331 images, 0 backgrounds, 0 corrupt: 100%|██████████| 331/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train63\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.03, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(49c29f6d4ebf48e9a5c50f3f8da328a6) to http://127.0.0.1:5000\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train63\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.053      3.246       1.43         60        640: 100%|██████████| 26/26 [04:00<00:00,  9.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:53<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497    0.00238      0.354     0.0502     0.0312\n",
      "\n",
      "1 epochs completed in 0.083 hours.\n",
      "Optimizer stripped from runs\\detect\\train63\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train63\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train63\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:44<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497    0.00241      0.354     0.0505     0.0315\n",
      "              Backpack         95        117          0          0          0          0\n",
      "             Cellphone         55         76    0.00984      0.592      0.039     0.0198\n",
      "                 Drill         79         81   0.000886      0.556      0.046     0.0238\n",
      "     Fire extinguisher         85         95    0.00134      0.621      0.167      0.114\n",
      "              Survivor        117        128          0          0          0          0\n",
      "Speed: 3.3ms preprocess, 112.4ms inference, 0.0ms loss, 9.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train63\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 12:05:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run yolov8ndet at: http://127.0.0.1:5000/#/experiments/843375537309377713/runs/49c29f6d4ebf48e9a5c50f3f8da328a6.\n",
      "2024/08/05 12:05:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/843375537309377713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to http://127.0.0.1:5000\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 12:05:38 INFO mlflow.types.utils: Unsupported type hint: <class 'dict'>, skipping schema inference\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 125.95it/s]\n",
      "Registered model 'yolov8ndet' already exists. Creating a new version of this model...\n",
      "2024/08/05 12:05:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: yolov8ndet, version 11\n",
      "Created version '11' of model 'yolov8ndet'.\n",
      "2024/08/05 12:05:38 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/05 12:05:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run fun-gnu-699 at: http://127.0.0.1:5000/#/experiments/275689030631216605/runs/770fcd33baf64af2ba02ffb4d5e90613.\n",
      "2024/08/05 12:05:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/275689030631216605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-05 12:05:38,649: INFO: 2215763116: artifact_uri = mlflow-artifacts:/843375537309377713/e0e995d16c7b4d1a8ebc0fac34bb4b38/artifacts]\n",
      "[2024-08-05 12:05:38,649: INFO: 2215763116: runID: 770fcd33baf64af2ba02ffb4d5e90613]\n",
      "[2024-08-05 12:05:38,649: INFO: 2215763116: experiment_id: 275689030631216605]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 12:05:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run efficient-stoat-96 at: http://127.0.0.1:5000/#/experiments/843375537309377713/runs/e0e995d16c7b4d1a8ebc0fac34bb4b38.\n",
      "2024/08/05 12:05:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/843375537309377713.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    xy = ConfigurationManager()\n",
    "    trainlog = xy.get_train_log_config()\n",
    "    valc = xy.get_datavalidation_config()\n",
    "    paramss = xy.get_params()\n",
    "    x = ModelTrainer(config=trainlog, val=valc,param=paramss)\n",
    "    x.train_model()\n",
    "\n",
    "    runs_f = get_highest_train_folder(\"runs/detect\")\n",
    "    dirr = Path(f\"runs/detect/{runs_f}\")\n",
    "\n",
    "    register_model(experiment_name=trainlog.experiment_name,\n",
    "                   model_name=trainlog.model_name,\n",
    "                   save_dir=dirr)\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-05 10:12:35,955: INFO: common: yaml file: config\\config.yaml loaded sucessfully]\n",
      "[2024-08-05 10:12:35,961: INFO: common: yaml file: params.yaml loaded sucessfully]\n",
      "[2024-08-05 10:12:35,963: INFO: common: created directory at artifacts]\n",
      "[2024-08-05 10:12:35,966: INFO: common: created directory at artifacts/data_validation]\n",
      "[2024-08-05 10:12:35,968: INFO: 4122740354: Dataset location: artifacts/data_ingestion/data\\data.yaml]\n",
      "[2024-08-05 10:12:35,971: INFO: 4122740354: CUDA is not available]\n",
      "[2024-08-05 10:12:35,972: INFO: 4122740354: Device to run on: cpu]\n",
      "[2024-08-05 10:12:35,972: INFO: 4122740354: artifacts/data_ingestion/data\\data.yaml]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.73 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=artifacts/data_ingestion/data\\data.yaml, epochs=1, time=None, patience=100, batch=24, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train62, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.03, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train62\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\train\\labels.cache... 624 images, 0 backgrounds, 0 corrupt: 100%|██████████| 624/624 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\valid\\labels.cache... 331 images, 0 backgrounds, 0 corrupt: 100%|██████████| 331/331 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train62\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.03, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005625000000000001), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(981dec4126304493b1f323a01a1bd72a) to http://127.0.0.1:5000\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train62\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.053      3.246       1.43         60        640: 100%|██████████| 26/26 [04:23<00:00, 10.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [01:00<00:00,  8.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497    0.00238      0.354     0.0502     0.0312\n",
      "\n",
      "1 epochs completed in 0.091 hours.\n",
      "Optimizer stripped from runs\\detect\\train62\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train62\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train62\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:47<00:00,  6.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497    0.00241      0.354     0.0505     0.0315\n",
      "              Backpack         95        117          0          0          0          0\n",
      "             Cellphone         55         76    0.00984      0.592      0.039     0.0198\n",
      "                 Drill         79         81   0.000886      0.556      0.046     0.0238\n",
      "     Fire extinguisher         85         95    0.00134      0.621      0.167      0.114\n",
      "              Survivor        117        128          0          0          0          0\n",
      "Speed: 3.5ms preprocess, 120.6ms inference, 0.0ms loss, 10.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train62\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 10:19:06 INFO mlflow.tracking._tracking_service.client: 🏃 View run yolov8ndet at: http://127.0.0.1:5000/#/experiments/843375537309377713/runs/981dec4126304493b1f323a01a1bd72a.\n",
      "2024/08/05 10:19:06 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/843375537309377713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to http://127.0.0.1:5000\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj2 = ConfigurationManager()\n",
    "    model_config = obj2.get_train_log_config()\n",
    "    valc = obj2.get_datavalidation_config()\n",
    "    params = obj2.get_params()\n",
    "    x = ModelTrainer(config=model_config, val=valc, param=params)\n",
    "    x.train_model()\n",
    "    #x.log_into_mlflow2()\n",
    "    #x.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise AppException(e, sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-02 17:38:58,388: INFO: common: yaml file: config\\config.yaml loaded sucessfully]\n",
      "[2024-08-02 17:38:58,393: INFO: common: yaml file: params.yaml loaded sucessfully]\n",
      "[2024-08-02 17:38:58,395: INFO: common: created directory at artifacts]\n",
      "[2024-08-02 17:38:58,396: INFO: common: created directory at artifacts/data_validation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/02 17:38:58 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI:  http://127.0.0.1:5000\n",
      "8efebb9c90134454861cd2b4e645ac17\n",
      "[2024-08-02 17:38:58,905: INFO: 2200128603: Dataset location: artifacts/data_ingestion/data\\data.yaml]\n",
      "[2024-08-02 17:38:58,905: INFO: 2200128603: CUDA is not available]\n",
      "[2024-08-02 17:38:58,905: INFO: 2200128603: Device to run on: cpu]\n",
      "[2024-08-02 17:38:58,909: INFO: 2200128603: artifacts/data_ingestion/data\\data.yaml]\n",
      "New https://pypi.org/project/ultralytics/8.2.71 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=artifacts/data_ingestion/data\\data.yaml, epochs=1, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train44, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.02, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/02 17:39:01 INFO mlflow.tracking._tracking_service.client: 🏃 View run yolov8det at: http://127.0.0.1:5000/#/experiments/895467674014368248/runs/8efebb9c90134454861cd2b4e645ac17.\n",
      "2024/08/02 17:39:01 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/895467674014368248.\n"
     ]
    },
    {
     "ename": "AppException",
     "evalue": "Error occured in python script name [C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_28176\\2631944331.py] line number [7] error message [Error occured in python script name [C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_28176\\2200128603.py] line number [108] error message [Dataset 'artifacts/data_ingestion/data/data.yaml' error  'artifacts/data_ingestion/data\\data.yaml' does not exist]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\engine\\trainer.py:528\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    527\u001b[0m }:\n\u001b[1;32m--> 528\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\data\\utils.py:269\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\utils\\checks.py:509\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'artifacts/data_ingestion/data\\data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 108\u001b[0m, in \u001b[0;36mModelTrainer.run_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_into_mlflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[12], line 88\u001b[0m, in \u001b[0;36mModelTrainer.log_into_mlflow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(run_id)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msave_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainedv8.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 54\u001b[0m, in \u001b[0;36mModelTrainer.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39msave(save_path)\n",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\engine\\model.py:805\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\engine\\trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\engine\\trainer.py:532\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'artifacts/data_ingestion/data/data.yaml' error  'artifacts/data_ingestion/data\\data.yaml' does not exist",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAppException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      6\u001b[0m     x \u001b[38;5;241m=\u001b[39m ModelTrainer(config\u001b[38;5;241m=\u001b[39mmodel_config, val\u001b[38;5;241m=\u001b[39mvalc, param\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[12], line 110\u001b[0m, in \u001b[0;36mModelTrainer.run_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AppException(e, sys)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAppException\u001b[0m: Error occured in python script name [C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_28176\\2200128603.py] line number [108] error message [Dataset 'artifacts/data_ingestion/data/data.yaml' error  'artifacts/data_ingestion/data\\data.yaml' does not exist]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAppException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     x\u001b[38;5;241m.\u001b[39mrun_pipeline()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AppException(e, sys)\n",
      "\u001b[1;31mAppException\u001b[0m: Error occured in python script name [C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_28176\\2631944331.py] line number [7] error message [Error occured in python script name [C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_28176\\2200128603.py] line number [108] error message [Dataset 'artifacts/data_ingestion/data/data.yaml' error  'artifacts/data_ingestion/data\\data.yaml' does not exist]]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj2 = ConfigurationManager()\n",
    "    model_config = obj2.get_train_log_config()\n",
    "    valc = obj2.get_datavalidation_config()\n",
    "    params = obj2.get_params()\n",
    "    x = ModelTrainer(config=model_config, val=valc, param=params)\n",
    "    x.run_pipeline()\n",
    "except Exception as e:\n",
    "    raise AppException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelTrainer' object has no attribute 'log_into_mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_into_mlflow\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModelTrainer' object has no attribute 'log_into_mlflow'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-29 00:59:56,601: INFO: common: yaml file: config\\config.yaml loaded sucessfully]\n",
      "[2024-07-29 00:59:56,604: INFO: common: yaml file: params.yaml loaded sucessfully]\n",
      "[2024-07-29 00:59:56,604: INFO: common: created directory at artifacts]\n",
      "[2024-07-29 00:59:56,605: INFO: common: created directory at artifacts/data_ingestion]\n",
      "[2024-07-29 00:59:56,606: INFO: 1550852978: Dataset location: artifacts/data_ingestion/data\\data.yaml]\n",
      "[2024-07-29 00:59:56,607: INFO: 1550852978: CUDA is not available]\n",
      "[2024-07-29 00:59:56,607: INFO: 1550852978: Device to run on: cpu]\n",
      "[2024-07-29 00:59:56,607: INFO: 1550852978: artifacts/data_ingestion/data\\data.yaml]\n",
      "New https://pypi.org/project/ultralytics/8.2.68 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=artifacts/data_ingestion/data\\data.yaml, epochs=1, time=None, patience=100, batch=5, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train10\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aravi\\anaconda3\\envs\\MLOPs\\lib\\site-packages\\ultralytics\\engine\\trainer.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\train\\labels... 2326 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2326/2326 [00:06<00:00, 354.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\valid\\labels... 331 images, 0 backgrounds, 0 corrupt: 100%|██████████| 331/331 [00:01<00:00, 272.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: X:\\DL\\Projects\\MLOPs\\artifacts\\data_ingestion\\data\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005078125), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      1.326      2.858      1.536          5        640: 100%|██████████| 466/466 [12:00<00:00,  1.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:42<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497      0.499      0.537      0.502      0.245\n",
      "\n",
      "1 epochs completed in 0.213 hours.\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.67  Python-3.9.19 torch-2.4.0+cpu CPU (AMD Ryzen 7 5825U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 34/34 [00:34<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        331        497      0.513      0.529      0.505      0.246\n",
      "              Backpack         95        117      0.721      0.575      0.706      0.359\n",
      "             Cellphone         55         76      0.395      0.474       0.36      0.214\n",
      "                 Drill         79         81      0.394      0.469      0.408      0.162\n",
      "     Fire extinguisher         85         95      0.468      0.574      0.507      0.211\n",
      "              Survivor        117        128      0.589      0.555      0.542      0.286\n",
      "Speed: 2.5ms preprocess, 84.9ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj2 = ConfigurationManager()\n",
    "    model_config = obj2.get_model_trainer()\n",
    "    dirc = obj2.get_dataingestion_config()\n",
    "    x = ModelTrainer(config=model_config, dir=dirc)\n",
    "    x.train_model()\n",
    "except Exception as e:\n",
    "    raise AppException(e, sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOPs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
