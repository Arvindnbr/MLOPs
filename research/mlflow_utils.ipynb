{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model wrapper\n",
    "class YoloWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.result = None\n",
    "        self.results_df = None\n",
    "        self.data = None\n",
    "\n",
    "    def load_context(self, context:object):\n",
    "        logging.info(f\"context.artifact[path]:{context.artifacts['path']}\")\n",
    "        self.model = YOLO(context.artifacts[\"path\"])\n",
    "        #dictonary to numpy arrays\n",
    "    def reformat_data(self):\n",
    "        #np array to str\n",
    "        for key, value in self.data.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                self.data[key] = \",\".join(map(str, [value]))\n",
    "                #value -> string\n",
    "        for key, value in self.data.items():\n",
    "            if value.isnumeric():\n",
    "                self.data[key] = int(value)\n",
    "            elif value.replace(\".\", \"\", 1).isdigit():\n",
    "                self.data[key] = float(value)\n",
    "            elif value.lower() in [\"true\",\"false\"]:\n",
    "                self.data[key] = value.lower() == \"true\"\n",
    "\n",
    "    def yolo_results_to_df(self):\n",
    "\n",
    "        # Retrieve bounding boxes\n",
    "        boxes = self.results[0].boxes\n",
    "        # Map class to string names\n",
    "        names = []\n",
    "        for object_class in boxes.cls.numpy():\n",
    "            names.append(self.model.names[object_class])\n",
    "        # Create return df\n",
    "        self.results_df = pd.DataFrame(\n",
    "            np.c_[boxes.xyxy.numpy(), boxes.conf, boxes.cls.numpy(), np.array(names)],\n",
    "            columns=[\"X1\", \"Y1\", \"X2\", \"Y2\", \"conf\", \"cls\", \"names\"],\n",
    "        )\n",
    "\n",
    "    def predict(self, context: object, data: dict):\n",
    "       \n",
    "        self.data = data\n",
    "        logging.info(f\"Data input: f{self.data}\")\n",
    "        # Reformat data\n",
    "        self.reformat_data()\n",
    "        logging.info(f\"Data after reformat: f{self.data}\")\n",
    "\n",
    "        # Pass inputs to predict\n",
    "        self.results = self.model.predict(**self.data)\n",
    "        # Transform results to pandas df\n",
    "        self.yolo_results_to_df()\n",
    "\n",
    "        return self.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Registers model in MLFlow\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import logging\n",
    "import yaml\n",
    "import cloudpickle\n",
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "def get_experiment_id(name: str):\n",
    "    \"\"\"Retrieve experiment if registered name, else create experiment.\n",
    "\n",
    "    Args:\n",
    "        name (str): Mlflow experiment name\n",
    "\n",
    "    Returns:\n",
    "        str: Mlfow experiment id\n",
    "    \"\"\"\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(name)\n",
    "        return exp_id\n",
    "    return exp.experiment_id\n",
    "\n",
    "\n",
    "def read_lines(path: str):\n",
    "    \"\"\"Given a path to a file, this function reads file, seperates the lines and returns a list of those separated lines.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to file\n",
    "\n",
    "    Returns:\n",
    "        list: List made of of file lines\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "\n",
    "def log_metrics(save_dir: str, log_results: bool = True):\n",
    "    \"\"\"Log metrics to Mlflow from the Yolo model outputs.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): Path to Yolo save directory, i.e - runs/train\n",
    "        log_results (bool): If True, the results are logged to MLflow server\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    try:\n",
    "        with open(save_dir / \"results.csv\", \"r\") as csv_file:\n",
    "            metrics_reader = csv.DictReader(csv_file)\n",
    "            metrics_list = []\n",
    "            for metrics in metrics_reader:\n",
    "                # Create an empty dictionary to store the updated key-value pairs for this row\n",
    "                updated_metrics = {}\n",
    "                # Iterate through the key-value pairs in this row's dictionary\n",
    "                for key, value in metrics.items():\n",
    "                    # Remove whitespace from the key\n",
    "                    key = key.strip()\n",
    "                    value = value.strip()\n",
    "                    # Remove extra strings in keys\n",
    "                    patterns = [\"(B)\", \"metrics/\"]\n",
    "                    for pattern in patterns:\n",
    "                        key = key.replace(pattern, \"\")\n",
    "                    # Add the updated key-value pair to the updated row dictionary\n",
    "                    try:\n",
    "                        # Add the updated key-value pair to the updated row dictionary\n",
    "                        updated_metrics[key] = float(value)\n",
    "                    except ValueError:\n",
    "                        logging.error(f\"ValueError: Could not convert {value} to float.\")\n",
    "                    metrics_list.append(updated_metrics)\n",
    "                    if log_results:\n",
    "                        mlflow.log_metrics(updated_metrics)\n",
    "        return metrics_list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FileNotFoundError: Could not find {save_dir / 'results.csv'}.\")\n",
    "    except IOError:\n",
    "        print(f\"IOError: Could not read {save_dir / 'results.csv'}.\")\n",
    "\n",
    "\n",
    "def get_path_w_extension(\n",
    "    path: str, extension: str, limit: int, ignore_files: list = []\n",
    "):\n",
    "    \"\"\"Finds files that match extensions and returns a list of those files that match up to thhe limit while ignoring files in the ignore_files list.\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory to search for files in.\n",
    "        extension (str): Type of extension to look for.\n",
    "        ignore_files (list, optional): Specify list of files that will be ignored. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        list: List of paths to files with extensions.\n",
    "    \"\"\"\n",
    "    logging.debug(f\"Path: {path}\")\n",
    "    logging.debug(f\"Extension: {extension}\")\n",
    "    if isinstance(path, str):\n",
    "        abs_path = os.path.abspath(path)\n",
    "    elif isinstance(path, Path):\n",
    "        abs_path = path.absolute()\n",
    "    else:\n",
    "        raise ValueError(f\"Error: Path {path} is not valid.\")\n",
    "\n",
    "    if not os.path.exists(abs_path):\n",
    "        raise ValueError(f\"Error: Path {abs_path} does not exist.\")\n",
    "\n",
    "    if os.path.isdir(abs_path):\n",
    "        pt_files = []\n",
    "        for root, dirs, files in os.walk(abs_path):\n",
    "            for file in files:\n",
    "                if (\n",
    "                    file.endswith(extension)\n",
    "                    and os.path.basename(file) not in ignore_files\n",
    "                ):\n",
    "                    pt_files.append(os.path.join(root, file))\n",
    "        if len(pt_files) <= limit and len(pt_files) > 0:\n",
    "            return pt_files\n",
    "        if len(pt_files) > limit:\n",
    "            raise ValueError(\n",
    "                f\"Error: Given limit: {limit} while number of files found with {extension} extension in directory {abs_path} is {len(pt_files)}\"\n",
    "            )\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Error: No {extension} files found in directory {abs_path}.\"\n",
    "            )\n",
    "    elif os.path.isfile(abs_path) and abs_path.endswith(extension):\n",
    "        return [abs_path]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Error: Path {abs_path} is not a valid directory or {extension} file.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def register_model(experiment_name: str, model_name: str, save_dir: Path):\n",
    "    \"\"\"Registers a model with mlflow\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name of Mlfow experiment\n",
    "        model_name (str): Name that will be registered with Mlflow\n",
    "        save_dir (Path): Path object where the results of the Yolo model are saved. I.e 'runs' directory\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    logging.debug(f\"Save Directory: {save_dir}\")\n",
    "\n",
    "    model_path = get_path_w_extension(\n",
    "        path=save_dir, extension=\".pt\", limit=1, ignore_files=[\"last.pt\"]\n",
    "    )[0]\n",
    "    artifacts = {\"path\": model_path}\n",
    "\n",
    "    model = YoloWrapper()\n",
    "\n",
    "    exp_id = get_experiment_id(experiment_name)\n",
    "\n",
    "    cloudpickle.register_pickle_by_value(model_wrapper)\n",
    "\n",
    "    with mlflow.start_run(experiment_id=exp_id) as run:\n",
    "        # Log some params\n",
    "        with open(save_dir / \"args.yaml\", \"r\") as param_file:\n",
    "            params = yaml.safe_load(param_file)\n",
    "        mlflow.log_params(params)\n",
    "        log_metrics(save_dir)\n",
    "        for file in sorted(save_dir.glob(\"*.png\")):\n",
    "            mlflow.log_artifact(file)\n",
    "        pip_reqs = read_lines(\"requirements.txt\")\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"model\",\n",
    "            python_model=model,\n",
    "            pip_requirements=pip_reqs,\n",
    "            artifacts=artifacts,\n",
    "            registered_model_name=model_name,\n",
    "        )\n",
    "        run_id = run.info.run_uuid\n",
    "        experiment_id = run.info.experiment_id\n",
    "        mlflow.end_run()\n",
    "        logging.info(f\"artifact_uri = {mlflow.get_artifact_uri()}\")\n",
    "        logging.info(f\"runID: {run_id}\")\n",
    "        logging.info(f\"experiment_id: {experiment_id}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    pass  # TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOPs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
